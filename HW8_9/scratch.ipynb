{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec_path = \"models/GoogleNews-vectors-negative300-SLIM\"\n",
    "# w2v_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "#     word2vec_path + \".bin.gz\", binary=True\n",
    "# )\n",
    "# w2v_model.save(word2vec_path + \".kv\")\n",
    "# del word2vec_path\n",
    "# del w2v_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"glove-wiki-gigaword-300\"\n",
    "# model = \"word2vec-google-news-300\" # too big\n",
    "model = \"GoogleNews-vectors-negative300-SLIM\"\n",
    "# model = \"fasttext-wiki-news-subwords-300\"\n",
    "# model = \"glove-twitter-200\"\n",
    "if (model + \".kv\") in os.listdir(\"models\"):\n",
    "    word2vec = gensim.models.KeyedVectors.load(f\"models/{model}.kv\")\n",
    "else:\n",
    "    word2vec: gensim.models.word2vec.KeyedVectors = gensim.downloader.load(model)\n",
    "    word2vec.save(f\"models/{model}.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yacht', 0.5311225056648254),\n",
       " ('boat', 0.48425018787384033),\n",
       " ('catamaran', 0.4792361259460449),\n",
       " ('powerboat', 0.4713691473007202),\n",
       " ('ketch', 0.4468856751918793)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar([\"king\", \"sailboat\"], [\"sparrow\"], topn=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mammoth' 'ray' 'change' 'knight' 'point']\n",
      " ['brush' 'drop' 'swing' 'mouth' 'crown']\n",
      " ['bow' 'bill' 'net' 'ham' 'kid']\n",
      " ['tablet' 'plot' 'chair' 'mexico' 'shoe']\n",
      " ['tooth' 'post' 'pin' 'lead' 'pirate']]\n"
     ]
    }
   ],
   "source": [
    "# Create a codenames board\n",
    "with open(\"wordlist-eng.txt\") as f:\n",
    "    words = f.readlines()\n",
    "    words = [word.strip().lower() for word in words]\n",
    "board = np.random.choice(words, size=(5, 5), replace=False)\n",
    "print(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Words: ['lead' 'chair' 'drop' 'swing' 'knight' 'tablet' 'pin' 'mammoth']\n",
      "Blue Words: ['pirate' 'post' 'net' 'change' 'point' 'brush' 'crown' 'ham' 'mexico']\n",
      "Assassin: mouth\n"
     ]
    }
   ],
   "source": [
    "# Create a team card\n",
    "special_words = np.random.choice(range(25), size=18, replace=False)\n",
    "flat_board = board.flatten()\n",
    "red_words = flat_board[special_words[:8]]\n",
    "blue_words = flat_board[special_words[8:17]]\n",
    "assassin = flat_board[special_words[17]]\n",
    "print(f\"Red Words: {red_words}\")\n",
    "print(f\"Blue Words: {blue_words}\")\n",
    "print(f\"Assassin: {assassin}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_common_substring(a, b, min_length=3):\n",
    "    \"\"\"\n",
    "    Check if any substring of length >= min_length from string `a` is in string `b`.\n",
    "\n",
    "    :param a: First string\n",
    "    :param b: Second string\n",
    "    :param min_length: Minimum length of the substring (default: 2)\n",
    "    :return: True if any substring of length >= min_length in `a` is in `b`, otherwise False\n",
    "    \"\"\"\n",
    "    len_a = len(a)\n",
    "    for start in range(len_a):\n",
    "        for end in range(start + min_length, len_a + 1):\n",
    "            substring = a[start:end]\n",
    "            if substring in b:\n",
    "                return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('pirate', 'post') ('buccaneers', 0.4359492361545563)\n",
      "('pirate', 'net') ('buccaneer', 0.45381754636764526)\n",
      "('pirate', 'change') ('alter', 0.48260003328323364)\n",
      "('pirate', 'point') ('Arrr', 0.40302774310112)\n",
      "('pirate', 'brush') ('lubbers', 0.44780853390693665)\n",
      "('pirate', 'crown') ('title', 0.5656847953796387)\n",
      "('pirate', 'ham') ('eggers', 0.5003951787948608)\n",
      "('pirate', 'mexico') ('caribbean', 0.5270410180091858)\n",
      "('post', 'net') ('period', 0.4296586811542511)\n",
      "('post', 'change') ('alter', 0.5471648573875427)\n",
      "('post', 'point') ('juncture', 0.388338565826416)\n",
      "('post', 'brush') ('deadfall', 0.38540056347846985)\n",
      "('post', 'crown') ('title', 0.5740607976913452)\n",
      "('post', 'ham') ('turkey', 0.4413197636604309)\n",
      "('post', 'mexico') ('usa', 0.5434982776641846)\n",
      "('net', 'change') ('adjustment', 0.5015605688095093)\n",
      "('net', 'point') ('goal', 0.5194658637046814)\n",
      "('net', 'brush') ('forehanded', 0.43671202659606934)\n",
      "('net', 'crown') ('title', 0.5637132525444031)\n",
      "('net', 'ham') ('escalopes', 0.4732958972454071)\n",
      "('net', 'mexico') ('usa', 0.5077977180480957)\n",
      "('change', 'point') ('shift', 0.5398156642913818)\n",
      "('change', 'brush') ('alter', 0.5279719233512878)\n",
      "('change', 'crown') ('title', 0.5629333853721619)\n",
      "('change', 'ham') ('alter', 0.4980427622795105)\n",
      "('change', 'mexico') ('alter', 0.5205531716346741)\n",
      "('point', 'brush') ('deadfall', 0.3891459107398987)\n",
      "('point', 'crown') ('title', 0.5844994783401489)\n",
      "('point', 'ham') ('bacon', 0.47940221428871155)\n",
      "('point', 'mexico') ('usa', 0.48475176095962524)\n",
      "('brush', 'crown') ('title', 0.521336555480957)\n",
      "('brush', 'ham') ('rissoles', 0.5237932801246643)\n",
      "('brush', 'mexico') ('albuquerque', 0.4888153672218323)\n",
      "('crown', 'ham') ('title', 0.5411087274551392)\n",
      "('crown', 'mexico') ('title', 0.5241341590881348)\n",
      "('ham', 'mexico') ('frijoles', 0.5746333003044128)\n",
      "best clue: ['title', 0.5844994783401489, ('point', 'crown')]\n"
     ]
    }
   ],
   "source": [
    "# generate a 2-word clue for red team\n",
    "clue = [\"\", 0, (\"\", \"\")]\n",
    "bad_words = tuple(list(blue_words) + list(assassin))\n",
    "\n",
    "\n",
    "def find_best_hint(words):\n",
    "    for subset in itertools.combinations(blue_words, 2):\n",
    "        similars = word2vec.most_similar(positive=list(subset), topn=15)\n",
    "        for attempt in similars:\n",
    "            # make sure the clue is not a word on the board\n",
    "            if attempt[0] in flat_board:\n",
    "                continue\n",
    "            # make sure ther clue is not a form of one of the prompts\n",
    "            if has_common_substring(attempt[0], subset[0]) or has_common_substring(\n",
    "                attempt[0], subset[1]\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            # if everything is good, pick this word as our clue\n",
    "            similar = attempt\n",
    "            break\n",
    "        if similar[1] > clue[1]:\n",
    "            clue = list(similar)\n",
    "            clue.append(subset)\n",
    "\n",
    "\n",
    "print(\"best clue:\", clue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['lead' 'chair' 'drop' 'swing' 'knight' 'tablet' 'pin' 'mammoth']\n",
      "worst removal: ['drop', 'swing']\n",
      "best pair: ['drop', 'swing']\n",
      "best 3: ['drop', 'swing', 'pin']\n",
      "best 4: ['lead', 'drop', 'swing', 'pin']\n",
      "best grouping:\n",
      "best pair: (('chair', 'knight'), 0.7760649)\n",
      "best 3: (('drop', 'swing', 'pin'), 0.6725464)\n",
      "best 4: (('lead', 'drop', 'swing', 'pin'), 0.6030851)\n"
     ]
    }
   ],
   "source": [
    "def cos_similar(a, b):\n",
    "    \"convenience function to calculate the cosine similarity between two vectors\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "\n",
    "# find the best 2-word pair\n",
    "def find_best_subset(word_list: list, set_size=2):\n",
    "    \"Finds the best subset of words by consecutive removal of the worst word\"\n",
    "    if len(word_list) == set_size:\n",
    "        return word_list\n",
    "    else:\n",
    "        word_list.remove(word2vec.doesnt_match(word_list))\n",
    "        return find_best_subset(word_list, set_size)\n",
    "\n",
    "\n",
    "print(\"words:\", red_words)\n",
    "print(\"worst removal:\", find_best_subset(list(red_words)))\n",
    "print(\"best pair:\", find_best_subset(list(red_words)))\n",
    "print(\"best 3:\", find_best_subset(list(red_words), 3))\n",
    "print(\"best 4:\", find_best_subset(list(red_words), 4))\n",
    "\n",
    "\n",
    "def find_best_subset(word_list: list, set_size=2):\n",
    "    \"Finds the best subset of words by rating all possible subsets\"\n",
    "    # generate all possible subsets\n",
    "    subsets = itertools.combinations(word_list, set_size)\n",
    "    best_subset = ([], 0)\n",
    "    for subset in subsets:\n",
    "        # first find the centroid of all the vectors\n",
    "        centroid = np.mean([word2vec[word] for word in subset], axis=0)\n",
    "        # then find the similarity of the centroid to each word in the subset\n",
    "        similarity = np.mean([cos_similar(word2vec[word], centroid) for word in subset])\n",
    "        # if the similarity is better than the current best, update the best\n",
    "        if similarity > best_subset[1]:\n",
    "            best_subset = (subset, similarity)\n",
    "    return best_subset\n",
    "\n",
    "\n",
    "print(\"best grouping:\")\n",
    "print(\"best pair:\", find_best_subset(list(red_words)))\n",
    "print(\"best 3:\", find_best_subset(list(red_words), 3))\n",
    "print(\"best 4:\", find_best_subset(list(red_words), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by finding thed best cluster of 2, 3, or 4 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get opencv up n runnin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
